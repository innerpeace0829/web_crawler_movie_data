{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c77446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 美國通膨率 資料爬取\n",
    "# 網址:https://www.minneapolisfed.org/about-us/monetary-policy/inflation-calculator/consumer-price-index-1913-\n",
    "url = f\"https://www.minneapolisfed.org/about-us/monetary-policy/inflation-calculator/consumer-price-index-1913-\"\n",
    "res = req.get(url,headers = {\"User-Agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36\"})\n",
    "soup = bs(res.text, \"lxml\")\n",
    "elements = soup.select(\"table td\")\n",
    "listUSCPI = [i.get_text() for i in elements]\n",
    "listColumnName = [\"Year\",\"Annual Average CPI(-U)\",\"Annual Percent Change(rate of inflation)\"]\n",
    "dfuscpi = pd.DataFrame(np.array(listUSCPI).reshape(-1,3),columns = listColumnName)\n",
    "dfuscpi[\"Year\"]=dfuscpi[\"Year\"].str.replace(\"\\n\",\"\").astype(\"int\")\n",
    "dfuscpi[\"Annual Average CPI(-U)\"]=dfuscpi[\"Annual Average CPI(-U)\"].str.replace(\"\\n\",\"\").astype(\"float\")\n",
    "dfuscpi[\"Annual Percent Change(rate of inflation)\"]=dfuscpi[\"Annual Percent Change(rate of inflation)\"].str.replace(\"\\n\",\"\").str.replace(\"%\",\"\")\n",
    "dfuscpi.loc[\"\"]=[2023,311.4,6.4]\n",
    "dfuscpi[\"Year\"]=dfuscpi[\"Year\"].astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40575df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# thenumbers 網站上的預算和票防資料爬蟲\n",
    "url = 'https://www.the-numbers.com/movie/budgets/all'\n",
    "res = req.get(url,headers = {'user-agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36'})\n",
    "soup = bs(res.text,\"lxml\")\n",
    "soup.select('table td')\n",
    "columns_list = ['ReleaseDate','Movie','ProductionBudget','DomesticGross','WorldwideGross']\n",
    "dfsum = pd.DataFrame(np.array([i.get_text() for i in soup.select('table td')]).reshape(-1,6)[:,1:6],columns = columns_list)\n",
    "index = 101\n",
    "for i in range(62):\n",
    "    url = f'https://www.the-numbers.com/movie/budgets/all/{index}'\n",
    "    res = req.get(url,headers = {'user-agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36'})\n",
    "    soup = bs(res.text,\"lxml\")\n",
    "    soup.select('table td')\n",
    "    dfsum = dfsum.append(pd.DataFrame(np.array([i.get_text() for i in soup.select('table td')]).reshape(-1,6)[:,1:6],columns = columns_list),ignore_index = True)\n",
    "    index += 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1ca4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMDB 電影評論爬蟲\n",
    "# 要修正\n",
    "\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests as req\n",
    "import json, os, pprint, time, re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "folderPath = 'IMDB'\n",
    "if not os.path.exists(folderPath):\n",
    "    os.makedirs(folderPath)\n",
    "row = [\"Title\", \"Author\", \"Date\", \"Up Vote\", \"Total Vote\", \"Rating\", \"Review\"]\n",
    "def get_IMDB_review(imdb_id):\n",
    "    global df\n",
    "\n",
    "    base_url = \"https://www.imdb.com/\"\n",
    "    url=f\"https://www.imdb.com/title/{imdb_id}/reviews?ref_=tt_ql_3\"\n",
    "    key = \"\"\n",
    "    res = req.get(url)\n",
    "    res.encoding = 'utf-8'\n",
    "    soup = bs(res.text, \"lxml\")\n",
    "    # 拜託啦\n",
    "    title = [item.select_one(\".title\").text for item in soup.select(\".lister-item-content\")]\n",
    "    author = [item.select_one(\".display-name-link\").text for item in soup.select(\".lister-item-content\")]\n",
    "    date = [item.select_one(\".review-date\").text for item in soup.select(\".lister-item-content\")]\n",
    "    upvote = [item.select_one('.actions.text-muted').text.split(sep=\" \")[20] for item in soup.select(\".lister-item-content\")]\n",
    "    totalvote = [item.select_one('.actions.text-muted').text.split(sep=\" \")[23] for item in soup.select(\".lister-item-content\")]\n",
    "    rating=[(item.select_one(\"span.rating-other-user-rating > span\").text if len(item.select(\"span.rating-other-user-rating > span\"))==2 else \"\") for item in soup.select(\".lister-item-content\") ]\n",
    "    review = [item.select_one('.text').text for item in soup.select(\".lister-item-content\")]\n",
    "\n",
    "    # 第二波找LOADMORE資料\n",
    "    load_more = soup.select_one(\".load-more-data\")\n",
    "    flag = True\n",
    "    # 找到load_more tag, 才需要往下抓\n",
    "    # 第二波的第一次抓loadmore\n",
    "    if load_more.text != '\\n':\n",
    "        ajaxurl = load_more['data-ajaxurl']\n",
    "        base_url = base_url + ajaxurl + \"?ref_=undefined&paginationKey=\"\n",
    "        key = load_more['data-key']\n",
    "    else :\n",
    "        while flag:\n",
    "            url = base_url + key\n",
    "        #     print(\"url = \", url)\n",
    "            res = req.get(url)\n",
    "            res.encoding = 'utf-8'\n",
    "            soup = bs(res.text, \"lxml\")\n",
    "            title2 = [item.select_one(\".title\").text for item in soup.select(\".lister-item-content\")]\n",
    "            title += title2\n",
    "            author2 = [item.select_one(\".display-name-link\").text for item in soup.select(\".lister-item-content\")]\n",
    "            author += author2\n",
    "            date2 = [item.select_one(\".review-date\").text for item in soup.select(\".lister-item-content\")]\n",
    "            date += date2\n",
    "            upvote2 = [item.select_one('.actions.text-muted').text.split(sep=\" \")[20] for item in soup.select(\".lister-item-content\")]\n",
    "            upvote += upvote2\n",
    "            totalvote2 = [item.select_one('.actions.text-muted').text.split(sep=\" \")[23] for item in soup.select(\".lister-item-content\")]\n",
    "            totalvote += totalvote2\n",
    "            rating2 =[(item.select_one(\"span.rating-other-user-rating > span\").text if len(item.select(\"span.rating-other-user-rating > span\"))==2 else \"\") for item in soup.select(\".lister-item-content\") ]\n",
    "            rating += rating2\n",
    "            review2 = [item.select_one('.text').text for item in soup.select(\".lister-item-content\")]\n",
    "            review += review2\n",
    "\n",
    "            load_more = soup.select_one(\".load-more-data\")\n",
    "            if load_more:\n",
    "                key = load_more['data-key']\n",
    "            else:\n",
    "                flag = False\n",
    "    sumlist = np.array((title, author, date, upvote, totalvote, rating, review))\n",
    "    length = sumlist.T.shape[0] \n",
    "    IMDBID = np.full((length,1),imdb_id)\n",
    "    convertnp = np.concatenate((IMDBID,sumlist.T),axis = 1)\n",
    "    df = pd.DataFrame(convertnp,columns = ['IMDBId','title', 'author', 'date', 'upvote', 'totalvote', 'rating', 'review'])\n",
    "#     df = pd.DataFrame(list(zip(title, author, date, upvote, totalvote, rating, review)), columns=row)\n",
    "    df.to_csv(f\"{folderPath}/{imdb_id}.csv\",index = False)\n",
    "#     print(df)\n",
    "    print(f\"{imdb_id} success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f81c9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmdb資料爬蟲 需要tmdb key\n",
    "from tmdbv3api import TMDb\n",
    "from tmdbv3api import Movie\n",
    "\n",
    "# id範圍\n",
    "max_id=330093\n",
    "min_id=300000\n",
    "# movie_ids=[]\n",
    "# # ng_list保留作預備用\n",
    "# movie_ng_ids=[]\n",
    "\n",
    "# movie_detail存放movie深層資料\n",
    "tmdb = TMDb()\n",
    "tmdb.api_key = 'a3c4a5cc98710d66e97acd6404ba8cd2'\n",
    "api_key = 'a3c4a5cc98710d66e97acd6404ba8cd2'\n",
    "movie = Movie()\n",
    "movie_detail=[]\n",
    "\n",
    "while True:\n",
    "    # API請求獲取電影淺層資訊\n",
    "    # 第二層要透過detail,這裡先不做\n",
    "    url=f'https://api.themoviedb.org/3/movie/{max_id}?api_key={api_key}&region=US&language=en-US'\n",
    "    response = req.get(url)\n",
    "    \n",
    "    # 淺層資訊獲取\n",
    "    data = json.loads(response.text)\n",
    "    \n",
    "    \n",
    "    if 'id' in data.keys():\n",
    "        print(f'Correct movie: {max_id}')\n",
    "        detail=movie.details(max_id)\n",
    "        movie_detail.append({\n",
    "            \"movie_id\": (\"NaN\" if detail.id==None else detail.id),\n",
    "            \"imdb_id\": (\"NaN\" if detail.imdb_id==None else detail.imdb_id),\n",
    "            \"title\": (\"NaN\" if detail.original_title==None else detail.original_title),\n",
    "            \"en_title\": (\"NaN\" if ([i['data']['title'] for i in detail['translations']['translations'] if i['iso_3166_1'] == 'US']==[]) else [i['data']['title'] for i in detail['translations']['translations'] if i['iso_3166_1'] == 'US'][0]),\n",
    "            \"budget\": (\"NaN\" if detail.budget==None else detail.budget),\n",
    "            \"revenue\": (\"NaN\" if detail.revenue==None else detail.revenue),\n",
    "            \"original_language\": (\"NaN\" if detail.original_language==None else detail.original_language),\n",
    "            \"release_date\": (\"NaN\" if detail.release_date==None else detail.release_date),\n",
    "            \"avg_rating\": (\"NaN\" if detail.vote_average==None else detail.vote_average),\n",
    "            \"vote_count\": (\"NaN\" if detail.vote_count==None else detail.vote_count),\n",
    "            \"sequal\": (\"NaN\" if detail.belongs_to_collection==None else detail.belongs_to_collection['name']),\n",
    "            \"casts\": (\"NaN\" if detail['casts']['cast']==None else [i['name'] for i in detail['casts']['cast']]),\n",
    "            \"keywords\": (\"NaN\" if detail['keywords']['keywords']==None else [i['name'] for i in detail['keywords']['keywords']]),\n",
    "            \"genres\": (\"NaN\" if detail['genres']==None else [i['name'] for i in detail['genres']]),\n",
    "            \"production_companies\": (\"NaN\" if detail['production_companies']==None else [i['name'] for i in detail['production_companies']]),\n",
    "            \"adult\": (\"NaN\" if detail.adult==None else detail.adult),\n",
    "            \"overview\": (\"NaN\" if detail.overview==None else detail.overview),\n",
    "            \"popularity\": (\"NaN\" if detail.popularity==None else detail.popularity),\n",
    "            \"production_countries\": (\"NaN\" if detail['production_countries']==None else [i['name'] for i in detail['production_countries']]),\n",
    "            \"runtime\": (\"NaN\" if detail.runtime==None else detail.runtime),\n",
    "            \"status\": (\"NaN\" if detail.status==None else detail.status),\n",
    "            \"tagline\": (\"NaN\" if detail.tagline==None else detail.tagline)\n",
    "        })\n",
    "    \n",
    "    else:\n",
    "        print(f'Incorrect movie id: {max_id}')\n",
    "    \n",
    "    max_id -=1\n",
    "    if max_id < min_id:\n",
    "        break\n",
    "\n",
    "# 把max_id原本值抓回來,以利輸出檔案的命名\n",
    "max_id=1093900\n",
    "\n",
    "\n",
    "\n",
    "with open(f\"raw_detail_{min_id}~{max_id}.json\",\"w\",encoding=\"utf-8\") as file:\n",
    "    file.write(json.dumps(movie_detail,ensure_ascii=False,indent=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
